{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Project Streamlit\n",
        "- modeling the Titanic dataset with **Pyspark**"
      ],
      "metadata": {
        "id": "PyJkWXbX6GbR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Course Name :         Applied Machine Learning\n",
        "- Course instructor:    Sohail Tehranipour\n",
        "- Student Name :        Afshin Masoudi Ashtiani\n",
        "- Chapter 7 -           Building a Web App for Data Scientists\n",
        "- Project:              Streamlit Project\n",
        "- Date :                September 2024"
      ],
      "metadata": {
        "id": "6aVvvA8e6OoS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Step 1: Install required libraries"
      ],
      "metadata": {
        "id": "y0W5z-kxfxKg"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9muh0a-UAMjR",
        "outputId": "d4f59dbf-d2bd-461e-d66d-42f8c9cf00a2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pyspark in /usr/local/lib/python3.10/dist-packages (3.5.2)\n",
            "Requirement already satisfied: py4j==0.10.9.7 in /usr/local/lib/python3.10/dist-packages (from pyspark) (0.10.9.7)\n"
          ]
        }
      ],
      "source": [
        "!pip install pyspark"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Step 2: Import required libraries\n",
        "\n"
      ],
      "metadata": {
        "id": "zlxBAbZQgCAp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pyspark\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ],
      "metadata": {
        "id": "PXWxaisECNN2"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Step 3: Start the Spark Session"
      ],
      "metadata": {
        "id": "Wkektv2YflXQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql import SparkSession\n",
        "spark = SparkSession.builder.appName('pyspark_titanic_model').getOrCreate()\n",
        "spark"
      ],
      "metadata": {
        "id": "eG9X61SICUaF",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 219
        },
        "outputId": "4e3baf12-1617-4c8e-ab01-93f422cddad4"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<pyspark.sql.session.SparkSession at 0x7bafc7c8a5f0>"
            ],
            "text/html": [
              "\n",
              "            <div>\n",
              "                <p><b>SparkSession - in-memory</b></p>\n",
              "                \n",
              "        <div>\n",
              "            <p><b>SparkContext</b></p>\n",
              "\n",
              "            <p><a href=\"http://26d851ab1e7a:4040\">Spark UI</a></p>\n",
              "\n",
              "            <dl>\n",
              "              <dt>Version</dt>\n",
              "                <dd><code>v3.5.2</code></dd>\n",
              "              <dt>Master</dt>\n",
              "                <dd><code>local[*]</code></dd>\n",
              "              <dt>AppName</dt>\n",
              "                <dd><code>pyspark_titanic_model</code></dd>\n",
              "            </dl>\n",
              "        </div>\n",
              "        \n",
              "            </div>\n",
              "        "
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Step 4: Load the dataset"
      ],
      "metadata": {
        "id": "I9XWxq43gLSl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the Drive helper and mount\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ge6qLI7aCyXc",
        "outputId": "0148694d-3b01-4c53-a187-30aca5e1bec9"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df = spark.read.csv('/content/drive/My Drive/Applied Machine Learning/Datasets/titanic_train.csv', header= True, inferSchema= True)\n",
        "df.printSchema()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gLHK0QAyH1Y3",
        "outputId": "26c5d4f8-41d6-45fc-a13c-48093859a647"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "root\n",
            " |-- PassengerId: integer (nullable = true)\n",
            " |-- Survived: integer (nullable = true)\n",
            " |-- Pclass: integer (nullable = true)\n",
            " |-- Name: string (nullable = true)\n",
            " |-- Sex: string (nullable = true)\n",
            " |-- Age: double (nullable = true)\n",
            " |-- SibSp: integer (nullable = true)\n",
            " |-- Parch: integer (nullable = true)\n",
            " |-- Ticket: string (nullable = true)\n",
            " |-- Fare: double (nullable = true)\n",
            " |-- Cabin: string (nullable = true)\n",
            " |-- Embarked: string (nullable = true)\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.describe().show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hcT51FAJItXL",
        "outputId": "deddb534-7d2a-46d4-f094-b56e166a2d20"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------+-----------------+-------------------+------------------+--------------------+------+------------------+------------------+-------------------+------------------+-----------------+-----+--------+\n",
            "|summary|      PassengerId|           Survived|            Pclass|                Name|   Sex|               Age|             SibSp|              Parch|            Ticket|             Fare|Cabin|Embarked|\n",
            "+-------+-----------------+-------------------+------------------+--------------------+------+------------------+------------------+-------------------+------------------+-----------------+-----+--------+\n",
            "|  count|              891|                891|               891|                 891|   891|               714|               891|                891|               891|              891|  204|     889|\n",
            "|   mean|            446.0| 0.3838383838383838| 2.308641975308642|                NULL|  NULL| 29.69911764705882|0.5230078563411896|0.38159371492704824|260318.54916792738| 32.2042079685746| NULL|    NULL|\n",
            "| stddev|257.3538420152301|0.48659245426485753|0.8360712409770491|                NULL|  NULL|14.526497332334035|1.1027434322934315| 0.8060572211299488|471609.26868834975|49.69342859718089| NULL|    NULL|\n",
            "|    min|                1|                  0|                 1|\"Andersson, Mr. A...|female|              0.42|                 0|                  0|            110152|              0.0|  A10|       C|\n",
            "|    max|              891|                  1|                 3|van Melkebeke, Mr...|  male|              80.0|                 8|                  6|         WE/P 5735|         512.3292|    T|       S|\n",
            "+-------+-----------------+-------------------+------------------+--------------------+------+------------------+------------------+-------------------+------------------+-----------------+-----+--------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.columns"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ed0x_3EDI9m5",
        "outputId": "a7c7e5ed-6c39-4f80-a0b1-07cf009ef6dc"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['PassengerId',\n",
              " 'Survived',\n",
              " 'Pclass',\n",
              " 'Name',\n",
              " 'Sex',\n",
              " 'Age',\n",
              " 'SibSp',\n",
              " 'Parch',\n",
              " 'Ticket',\n",
              " 'Fare',\n",
              " 'Cabin',\n",
              " 'Embarked']"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.dtypes"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Sm-ehgkVJEf5",
        "outputId": "4f6608a2-2f50-42f7-8b62-d5eb8dbdcd10"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('PassengerId', 'int'),\n",
              " ('Survived', 'int'),\n",
              " ('Pclass', 'int'),\n",
              " ('Name', 'string'),\n",
              " ('Sex', 'string'),\n",
              " ('Age', 'double'),\n",
              " ('SibSp', 'int'),\n",
              " ('Parch', 'int'),\n",
              " ('Ticket', 'string'),\n",
              " ('Fare', 'double'),\n",
              " ('Cabin', 'string'),\n",
              " ('Embarked', 'string')]"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Step 5: Import VectorAssembler module"
      ],
      "metadata": {
        "id": "fWJlEtUygp_s"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.ml.feature import VectorAssembler\n",
        "cols = ['Survived', 'Pclass', 'Age', 'SibSp', 'Parch', 'Fare']\n",
        "assembler_data = VectorAssembler(inputCols=cols, outputCol=\"features\", handleInvalid=\"skip\")\n",
        "output = assembler_data.transform(df)\n",
        "output.show(5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WSMGof0uJKIp",
        "outputId": "972a4cf0-4b28-4217-afdc-7ef11c687cc8"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----------+--------+------+--------------------+------+----+-----+-----+----------------+-------+-----+--------+--------------------+\n",
            "|PassengerId|Survived|Pclass|                Name|   Sex| Age|SibSp|Parch|          Ticket|   Fare|Cabin|Embarked|            features|\n",
            "+-----------+--------+------+--------------------+------+----+-----+-----+----------------+-------+-----+--------+--------------------+\n",
            "|          1|       0|     3|Braund, Mr. Owen ...|  male|22.0|    1|    0|       A/5 21171|   7.25| NULL|       S|[0.0,3.0,22.0,1.0...|\n",
            "|          2|       1|     1|Cumings, Mrs. Joh...|female|38.0|    1|    0|        PC 17599|71.2833|  C85|       C|[1.0,1.0,38.0,1.0...|\n",
            "|          3|       1|     3|Heikkinen, Miss. ...|female|26.0|    0|    0|STON/O2. 3101282|  7.925| NULL|       S|[1.0,3.0,26.0,0.0...|\n",
            "|          4|       1|     1|Futrelle, Mrs. Ja...|female|35.0|    1|    0|          113803|   53.1| C123|       S|[1.0,1.0,35.0,1.0...|\n",
            "|          5|       0|     3|Allen, Mr. Willia...|  male|35.0|    0|    0|          373450|   8.05| NULL|       S|[0.0,3.0,35.0,0.0...|\n",
            "+-----------+--------+------+--------------------+------+----+-----+-----+----------------+-------+-----+--------+--------------------+\n",
            "only showing top 5 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "final_df = output.select('features','Survived')\n",
        "final_df.show(5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ynEC1H4TiiYX",
        "outputId": "ed9d1e2e-bb8d-4d8d-f73e-aee69fcd527d"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------------------+--------+\n",
            "|            features|Survived|\n",
            "+--------------------+--------+\n",
            "|[0.0,3.0,22.0,1.0...|       0|\n",
            "|[1.0,1.0,38.0,1.0...|       1|\n",
            "|[1.0,3.0,26.0,0.0...|       1|\n",
            "|[1.0,1.0,35.0,1.0...|       1|\n",
            "|[0.0,3.0,35.0,0.0...|       0|\n",
            "+--------------------+--------+\n",
            "only showing top 5 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Step 6: Split the data into the train and test sets"
      ],
      "metadata": {
        "id": "gyAnumeWkxT3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_df, test_df = final_df.randomSplit([0.8, 0.2], seed=17)\n",
        "\n",
        "# Check that training set has around 80% of records\n",
        "training_ratio = train_df.count() / final_df.count()\n",
        "print(training_ratio)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TEbCuJjYk51X",
        "outputId": "066d1b27-8cd5-43e0-b296-2e6c41a57363"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.7997198879551821\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Step 7: Build Logistic Regression model using PySpark"
      ],
      "metadata": {
        "id": "GbIZZejCkB3a"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.ml.classification import LogisticRegression\n",
        "\n",
        "# Create classifier object and train on training data\n",
        "lr_model = LogisticRegression(featuresCol='features', labelCol='Survived').fit(train_df)\n",
        "lr_model.summary.predictions.show(5)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ENaKqs5epQHq",
        "outputId": "c31f0fc1-5cff-49aa-c51b-d1f2741438ba"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------------------+--------+--------------------+--------------------+----------+\n",
            "|            features|Survived|       rawPrediction|         probability|prediction|\n",
            "+--------------------+--------+--------------------+--------------------+----------+\n",
            "|(6,[1,2],[1.0,39.0])|     0.0|[18.6904721683158...|[0.99999999236461...|       0.0|\n",
            "|(6,[1,2],[1.0,40.0])|     0.0|[18.7044749124899...|[0.99999999247078...|       0.0|\n",
            "|(6,[1,2],[3.0,19.0])|     0.0|[19.1159503535575...|[0.99999999501060...|       0.0|\n",
            "|(6,[1,2],[3.0,36.0])|     0.0|[19.3539970045174...|[0.99999999606752...|       0.0|\n",
            "|(6,[1,2],[3.0,49.0])|     0.0|[19.5360326787808...|[0.99999999672200...|       0.0|\n",
            "+--------------------+--------+--------------------+--------------------+----------+\n",
            "only showing top 5 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "lr_model.summary.predictions.describe().show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tBL_D8mutYhG",
        "outputId": "10c6f1bb-f617-4a76-d6ab-86fd15cce3f6"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------+------------------+------------------+\n",
            "|summary|          Survived|        prediction|\n",
            "+-------+------------------+------------------+\n",
            "|  count|               571|               571|\n",
            "|   mean|0.4098073555166375|0.4098073555166375|\n",
            "| stddev|0.4922292270333013|0.4922292270333013|\n",
            "|    min|               0.0|               0.0|\n",
            "|    max|               1.0|               1.0|\n",
            "+-------+------------------+------------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.ml.evaluation import BinaryClassificationEvaluator\n",
        "test_pred_df = lr_model.evaluate(test_df)\n",
        "test_pred_df.predictions.show(5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NuzVY7eWuc9Y",
        "outputId": "647adc55-bec8-4093-d0b2-73f33e154388"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------------------+--------+--------------------+--------------------+----------+\n",
            "|            features|Survived|       rawPrediction|         probability|prediction|\n",
            "+--------------------+--------+--------------------+--------------------+----------+\n",
            "|(6,[1,2],[1.0,38.0])|       0|[18.6764694241416...|[0.99999999225694...|       0.0|\n",
            "|[0.0,1.0,2.0,1.0,...|       0|[17.8292428349916...|[0.99999998193415...|       0.0|\n",
            "|[0.0,1.0,22.0,0.0...|       0|[18.2450319489414...|[0.99999998807980...|       0.0|\n",
            "|[0.0,1.0,30.0,0.0...|       0|[18.5220156230867...|[0.99999999096369...|       0.0|\n",
            "|[0.0,1.0,31.0,0.0...|       0|[18.5012383196734...|[0.99999999077398...|       0.0|\n",
            "+--------------------+--------+--------------------+--------------------+----------+\n",
            "only showing top 5 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "eval = BinaryClassificationEvaluator(rawPredictionCol='prediction', labelCol='Survived')\n",
        "auc = eval.evaluate(test_pred_df.predictions)\n",
        "auc"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A0UD_jAau-qS",
        "outputId": "9594f134-6395-4cc1-f957-c7d6402fcabc"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1.0"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    }
  ]
}